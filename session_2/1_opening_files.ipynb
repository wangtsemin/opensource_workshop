{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python hands-on session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Ties de Kok  \n",
    "Version: Python 2.7 (see any notes for Python 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **handling files**\n",
    "2. data handling\n",
    "3. web scraping\n",
    "4. text mining\n",
    "5. (interactive) visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to open and save a wide variety of file formats using Python.  \n",
    "There are often multiple ways to open a particular file format, the examples below are what I like to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing a folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many instances you want to loop over all the files in a folder.  \n",
    "There are multiple ways to go about this but I like to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the folder contains only files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = r'C:\\Stack\\Work\\Workshops\\python_workshop'\n",
    "filenames = os.listdir(folder)\n",
    "filepaths = [os.path.join(folder, name) for name in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files are in multiple sub-folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the folder contains multiple levels we need to use a more advanced technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder = r'C:\\Stack\\Work\\Workshops\\python_workshop'\n",
    "filepaths = []\n",
    "for root,dirs,files in os.walk(folder):\n",
    "    for i in files:\n",
    "        filepaths.append(os.path.join(root,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening text files is done using the default Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open a file with different file modes:  \n",
    "w -> write only  \n",
    "r -> read only  \n",
    "w+ -> read and write + completely overwrite file  \n",
    "a+ -> read and write + append at the bottom  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'C:\\file.txt', 'w+') as file:\n",
    "    file_content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'C:\\file.txt', 'w+') as file:\n",
    "    file.write('Content of new file. \\nHi there!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I am using a `with` statement when opening files.  \n",
    "Another method is to use `open` and `close`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(r'C:\\file.txt', 'w+')\n",
    "file_content = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `with` method is prefered as it automatically closes the file.  \n",
    "This prevents the file from being 'in use' if you forget to use `.close()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over indexed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in filepaths:\n",
    "    with open(i, 'w+') as f:\n",
    "        file_content = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel and .csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to open these files, I like to use `Pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function has a lot of options, see:  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html  \n",
    "\n",
    "*Note:* You often want to add `, encoding='utf-8'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_file = pd.read_excel(r'C:\\file.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves a `Pandas` dataframe object, see the data handling file.  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html  \n",
    "\n",
    "*Note:* You can save as `.xls` but also `.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df.to_excel(r'C:\\file.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many many ways to open a CSV file, I will show the Pandas function.  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv(r'C:\\file.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df.to_csv(r'C:\\file.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stata and SAS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can also open and save Stata and open SAS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_stata.html  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_stata.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stata_file = pd.read_stata(r'C:\\file.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df.to_stata(r'C:\\file.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: make sure you have the latest version of Pandas for new Stata versions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sas.html  \n",
    "This function works in most cases but files with text can throw nasty encoding errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sas_file = pd.read_sas(r'C:\\file.sas7bdat', format='sas7bdat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON file to Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html  \n",
    "\n",
    "*Note:* The path can also be a url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_df = pd.read_json(r'C:\\file.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the `json` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'C:\\file.json', 'r') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "   'name' : 'Ties',\n",
    "   'location' : 'Tilburg',\n",
    "}\n",
    "\n",
    "with open(r'C:\\file.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You often run into the problem of having to store large amounts of data.  \n",
    "The traditional formats such as .csv are not very efficient as big-data file formats.  \n",
    "\n",
    "I like to use the `Hierarchical Data Format` or `HDF` in short.\n",
    "This `.hdf` file format is designed to store and organize large amounts of data. \n",
    "\n",
    "Writing and reading `.hdf` files is extremely fast compared to `.csv`:\n",
    "\n",
    "**Writing:**\n",
    "\n",
    "```\n",
    "%timeit test_hdf_fixed_write(df)\n",
    "1 loops, best of 3: 237 ms per loop\n",
    "\n",
    "%timeit test_hdf_table_write(df)\n",
    "1 loops, best of 3: 901 ms per loop\n",
    "\n",
    "%timeit test_csv_write(df)\n",
    "1 loops, best of 3: 3.44 s per loop\n",
    "```\n",
    "\n",
    "**Reading:**\n",
    "\n",
    "```\n",
    "%timeit test_hdf_fixed_read()\n",
    "10 loops, best of 3: 19.1 ms per loop\n",
    "\n",
    "%timeit test_hdf_table_read()\n",
    "10 loops, best of 3: 39 ms per loop\n",
    "\n",
    "%timeit test_csv_read()\n",
    "1 loops, best of 3: 620 ms per loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and write HDF files using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to read and write Pandas dataframes  \n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_hdf.html  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_hdf.html\n",
    "\n",
    "*Note*: You can give it any `key` you like. I always use the filename with `.h5` as `key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf_df = pd.read_hdf(r'C:\\file.h5', 'file') # Second argument is the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df.to_hdf(r'C:\\file.h5', 'file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using HDF with big data that does not fit into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One big advantage of `HDF` is that it does not require all the data to be load into memory at once. \n",
    "\n",
    "See the page below for a very comprehensive overview:  \n",
    "http://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
