{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By:** Ties de Kok and Jan Boone  \n",
    "**Python version:** 2.7 but will also work with 3.5 (see notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example: process files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to learn Python is by finding a problem that you want to solve using Python.  \n",
    "So in this example:\n",
    "\n",
    "**Problem:**\n",
    "\n",
    "I download a lot of working papers from SSRN but they all end up in my `Downloads` folder with cryptic names like `SSRN-id2645351.pdf`  \n",
    "\n",
    "**Desired solution:**  \n",
    "\n",
    "I want to write a script to check my `Downloads` folder for SSRN papers and categorize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good habit to always:  \n",
    "1. Mention which version of Python you are using\n",
    "2. Put your `imports` at the top of the file\n",
    "3. Define your working directory explicitly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some standard libraries that we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re, time, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: ** For Python 3 we need import `urllib` instead of `urllib2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the contents of PDF files we need a package called `PyPDF2`  \n",
    "**Note:** `PyPDF2` is third-party package, so we need to install it first:  \n",
    "1. Open up your command prompt\n",
    "2. Type: `pip install PyPDF2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complex data structures we use the `pandas` package.  \n",
    "This package is pre-installed by the Anaconda distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good habit to explicitly define your working directory.  \n",
    "This makes it easier to use the code across computers / people. \n",
    "\n",
    "By default the working directory is set to the location of the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Stack\\Work\\Workshops\\python_workshop\\opensource_workshop\\example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# scanning a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downloads_path = r'Downloads'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain a list of all the files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downloads_files = os.listdir(downloads_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to interactively check the contents of a variable, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['another_file.txt',\n",
       " 'SSRN-id1476561.pdf',\n",
       " 'SSRN-id1521584.pdf',\n",
       " 'SSRN-id1557231.pdf',\n",
       " 'SSRN-id156445.pdf',\n",
       " 'SSRN-id1670116.pdf',\n",
       " 'SSRN-id1786360.pdf']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloads_files[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a list with all the .pdf files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to do this, REGEX is the most powerful but can be complex.  \n",
    "An easier way is to just check whether the final 4 characters equal '.pdf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf_files = []\n",
    "for i in downloads_files:\n",
    "    if i[-4:] == '.pdf':\n",
    "        pdf_files.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSRN-id1476561.pdf',\n",
       " 'SSRN-id1521584.pdf',\n",
       " 'SSRN-id1557231.pdf',\n",
       " 'SSRN-id156445.pdf',\n",
       " 'SSRN-id1670116.pdf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only those files that start with 'SSRN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_files = []\n",
    "for i in pdf_files:\n",
    "    if i[:4] == 'SSRN':\n",
    "        ssrn_files.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSRN-id1476561.pdf',\n",
       " 'SSRN-id1521584.pdf',\n",
       " 'SSRN-id1557231.pdf',\n",
       " 'SSRN-id156445.pdf',\n",
       " 'SSRN-id1670116.pdf']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the number of SSRN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssrn_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Process the SSRN files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Remove duplicates using `set`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `set` is similar to a `list` but only contains unique values.  \n",
    "However, when downloading duplicate files the file name is appended by ` (1)` so `set` does not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn_files = set(ssrn_files)\n",
    "len(ssrn_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates using a regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression are very powerful to specify patterns but they are complicated to get right.  \n",
    "My personal approach is to use trial-and-error, these two websites makes this easier:  \n",
    "- [pyregex](http://pyregex.com/)\n",
    "- [pythex](http://pythex.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that the file-name follows a valid pattern.  \n",
    "`re.match('SSRN-id\\d{5,7}\\.pdf', i)` returns `True` if the filename is:  \n",
    "- `SSRN-id12345.pdf`\n",
    "- `SSRN-id123456.pdf`\n",
    "- `SSRN-id1234567.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_unique = [i for i in ssrn_files if re.match('SSRN-id\\d{5,7}\\.pdf', i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very powerful and useful feature of Python are the so-called `comprehensions`.  \n",
    "Above I used a `list comprehension` as noted by the brackets.  \n",
    "\n",
    "Essentially that one-line of code equals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssrn_unique_v2 = []\n",
    "for i in ssrn_files:\n",
    "    if re.match('SSRN-id\\d{5,7}\\.pdf', i):\n",
    "        ssrn_unique_v2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssrn_unique) == len(ssrn_unique_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssrn_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the download date for each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the creation time using `os.path.getctime()`.  \n",
    "To make it human readible we can convert it using `time.ctime()`  \n",
    "\n",
    "The most consistent way to dynamically create a path is to use `os.path.join()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Downloads\\\\SSRN-id2610429.pdf'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(downloads_path, ssrn_unique[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_ctime = {}\n",
    "for i in ssrn_unique:\n",
    "    path_file = os.path.join(downloads_path, i)\n",
    "    ssrn_ctime[i] = os.path.getctime(path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ssrn_ctime` is a dictionary. Each item consists of a `key` and a `value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ssrn_ctime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary is useful because it allows to retreive the `value` using the `key`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon May 09 16:19:21 2016'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.ctime(ssrn_ctime[ssrn_unique[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve information about the working paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to categorize the PDF files we need to obtain some more information about each file.  \n",
    "We can get this information from two sources:\n",
    "1. Open the PDF file using `PyPDF2`\n",
    "2. Use the file name to scrape information from the corresponding SSRN page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the PDF using PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf_file = PyPDF2.PdfFileReader(os.path.join(downloads_path, ssrn_unique[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Financial Accounting Research, Practice, and Financial Accountability   \n",
      " Invited Submission for Abacus 50th Anniversary Special Issue    Mary E. Barth Stanford University \n",
      " May 2015   \n",
      " \n",
      " I appreciate the helpful comments of Willia\n",
      "m Beaver, Greg Clinch, Wayne Landsman, James \n",
      "Leisenring, Warren McGregor, and Katherine Schipper.   \n"
     ]
    }
   ],
   "source": [
    "print(pdf_file.getPage(0).extractText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with PDF files is that they are aimed to be human readable, not machine readable.  \n",
    "This is especially problematic given that papers are not consistently formatted.  \n",
    "\n",
    "It is, therefore, easier to look for a different source of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Retrieve information from the SSRN page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the SSRN filename appear cryptic they actually contain a machine readible ID.  \n",
    "We can use the ID to construct a URL that leads to the corresponding SSRN webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:  \n",
    "The file `SSRN-id2610429.pdf` refers to ID: 2610429  \n",
    "We can create the SSRN url using this ID:  \n",
    "http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2610429"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a dictionary with the ID for each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to extract the ID from the filename.  \n",
    "We can do this with a Regular Expression: `'id(\\d{5,7})\\.pdf'`.  \n",
    "*Note:* we use `re.findall()` which always returns a `list`, therefore we add `[0]` to extract the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssrn_ID = {i : re.findall('id(\\d{5,7})\\.pdf', i)[0] for i in ssrn_unique}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* above I use a dictionary comprehension, this is equal to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_ID = {}\n",
    "for i in ssrn_unique:\n",
    "    ssrn_ID[i] = re.findall('id(\\d{5,7})\\.pdf', i)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2610429'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn_ID['SSRN-id2610429.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct URL based on ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will loop over a dictionary instead of a list.  \n",
    "Every item in a dictionary consists of two components: `key`, `value`.  \n",
    "To deal with this we define two variables (`k, v`) in the loop statement.  \n",
    "\n",
    "**Note:** In Python 2.7 we have to use `.iteritems()` in Python 3 this has been simplified to `.items()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_url = {}\n",
    "for k, v in ssrn_ID.iteritems():\n",
    "    url = 'http://papers.ssrn.com/sol3/papers.cfm?abstract_id=%s' % v\n",
    "    ssrn_url[k] = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2610429'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn_url['SSRN-id2610429.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve information from the webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to extract information from a webpage using Python.  \n",
    "Here we will use the most basic version that works fine for simple tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will open a webpage and retrieve the HTML source using the build-in `urllib2` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_text = urllib2.urlopen(ssrn_url['SSRN-id2610429.pdf']).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced HTML parsers such as `BeautifulSoup` allow you to select components based on their characteristics.  \n",
    "For this example we are going to use the easiest way and use Regular Expressions instead.  \n",
    "\n",
    "We are interested in the following items:  \n",
    "1. title\n",
    "2. author\n",
    "3. publication date\n",
    "\n",
    "If you check the HTML page source you will observe that these are included between `meta` tags:\n",
    "\n",
    "    <title>Financial Accounting Research, Practice, and Financial Accountability by Mary E. Barth :: SSRN</title>\n",
    "   \n",
    "    <meta name=\"citation_author\" content=\"Barth, Mary E.\">\n",
    "    <meta name=\"citation_title\" content=\"Financial Accounting Research, Practice, and Financial Accountability\">\n",
    "    <meta name=\"citation_online_date\" content=\"2015/05/26\">\n",
    "\n",
    "This makes it easy to extract the content using Regular Expressions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barth, Mary E.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'<meta name=\"citation_author\" content=\"(.*)\">', html_text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Financial Accounting Research, Practice, and Financial Accountability'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'<meta name=\"citation_title\" content=\"(.*)\">', html_text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015/05/26'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'<meta name=\"citation_online_date\" content=\"(.*)\">', html_text)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function that will extract everything when given an URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a loop that contains all these `re.findall()` statements gets messy really fast.  \n",
    "A better solution is to write a function and call the function in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack_list(list_in, authors=False):\n",
    "    if len(list_in) == 0: # Check whether the list is empty\n",
    "        return ''\n",
    "    elif authors:\n",
    "        return list_in\n",
    "    else:\n",
    "        return list_in[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function above deals with the case that the information is not provided.  \n",
    "`re.findall()` will then return an empty list which does not allow `[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_info(url):\n",
    "    html_text = urllib2.urlopen(url).read()\n",
    "    authors = unpack_list(re.findall(r'<meta name=\"citation_author\" content=\"(.*)\">', html_text), authors=True)\n",
    "    title = unpack_list(re.findall(r'<meta name=\"citation_title\" content=\"(.*)\">', html_text))\n",
    "    date = unpack_list(re.findall(r'<meta name=\"citation_online_date\" content=\"(.*)\">', html_text))\n",
    "    return(title, authors, date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call this function with any URL and it will return a `tuple` with the information.  \n",
    "A `tuple` is similar to a `list` but it is not mutable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Financial Accounting Research, Practice, and Financial Accountability',\n",
       " ['Barth, Mary E.'],\n",
       " '2015/05/26')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info(ssrn_url['SSRN-id2610429.pdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through all the PDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will loop through all the items in the `ssrn_url` dictionary.  \n",
    "**Note:**  \n",
    "SSRN will block our connection if we loop too fast. \n",
    "To deal with this problem we include two things:\n",
    "\n",
    "1. We use `try` and `except` to catch any errors when SSRN blocks the connection.\n",
    "2. Using `time.sleep(5)` if it fails so that Python will wait for 5 seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: 2477962\n",
      "Failed: 2477962\n",
      "Failed: 414522\n",
      "Failed: 2657333\n",
      "Failed: 555042\n"
     ]
    }
   ],
   "source": [
    "ssrn_details = {k : None for k, v in ssrn_url.iteritems()}\n",
    "for k, v in ssrn_url.iteritems():\n",
    "    while ssrn_details[k] == None:\n",
    "        try:\n",
    "            ssrn_details[k] = extract_info(v)\n",
    "        except:\n",
    "            print('Failed: ' + ssrn_ID[k])\n",
    "            time.sleep(5)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Do Changes in Reporting Frequency Really Influence Investors\\xe2\\x80\\x99 Risk Taking Behavior? Myopic Loss Aversion Revisited',\n",
       " ['Zeisberger, Stefan ', 'Langer, Thomas ', 'Weber, Martin '],\n",
       " '2011/03/20')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn_details['SSRN-id1786360.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorize the ssrn downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop invalid SSRN downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might happen that an ID is not found by SSRN, we would like to remove these.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_details_v2 = {}\n",
    "for k, v in ssrn_details.iteritems():\n",
    "    if v[0] != '' and v[1] != '':\n",
    "        ssrn_details_v2[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssrn_details.keys()) - len(ssrn_details_v2.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change filename and move to different folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a more informative name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the filename more descriptive of the working paper by changing it to:  \n",
    "`names (year)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_names = {}\n",
    "for k, v in ssrn_details_v2.iteritems():\n",
    "    name = ', '.join([re.findall('^(.*),', name)[0].strip() for name in v[1]]) + ' (' + v[2][:4] + ').pdf'\n",
    "    ssrn_names[k] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zeisberger, Langer, Weber (2011).pdf'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn_names['SSRN-id1786360.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the SSRN files with the new name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform 'file explorer' tasks using the build-in `shutil` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_folder = r'SSRN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the folder does not exist --> make it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(cat_folder):\n",
    "    os.makedirs(cat_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in ssrn_names.iteritems():\n",
    "    current = os.path.join(downloads_path, k)\n",
    "    destination = os.path.join(cat_folder, v)\n",
    "    try:\n",
    "        shutil.copy(current, destination)\n",
    "    except Exception as e:\n",
    "        print('Failed to copy %s' % v)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Excel file with all the details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a bunch of dictionaries with different pieces of information.  \n",
    "We can create on multi-level dictionary that contains everthing but using the `pandas` package is easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all the dictionaries into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we convert the `ssrn_names` dictionary into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_dataframe = pd.DataFrame.from_dict(ssrn_names, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssrn_dataframe.columns = ['new_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSRN-id2610429.pdf</th>\n",
       "      <td>Barth (2015).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSRN-id1786360.pdf</th>\n",
       "      <td>Zeisberger, Langer, Weber (2011).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSRN-id2596182.pdf</th>\n",
       "      <td>Ewert, Wagenhofer (2015).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSRN-id2373877.pdf</th>\n",
       "      <td>Bonetti, Cho, Michelon (2014).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSRN-id2678836.pdf</th>\n",
       "      <td>Chyz, Gaertner (2015).pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                new_name\n",
       "SSRN-id2610429.pdf                      Barth (2015).pdf\n",
       "SSRN-id1786360.pdf  Zeisberger, Langer, Weber (2011).pdf\n",
       "SSRN-id2596182.pdf          Ewert, Wagenhofer (2015).pdf\n",
       "SSRN-id2373877.pdf     Bonetti, Cho, Michelon (2014).pdf\n",
       "SSRN-id2678836.pdf             Chyz, Gaertner (2015).pdf"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add the details from `ssrn_ctime`, `ssrn_url`, and `ssrn_details_v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_dataframe['ctime'] = [time.ctime(ssrn_ctime[i]) for i in ssrn_dataframe.index]\n",
    "ssrn_dataframe['title'] = [ssrn_details_v2[i][0] for i in ssrn_dataframe.index]\n",
    "ssrn_dataframe['authors'] = [ssrn_details_v2[i][1] for i in ssrn_dataframe.index]\n",
    "ssrn_dataframe['ssrn_date'] = [ssrn_details_v2[i][2] for i in ssrn_dataframe.index]\n",
    "ssrn_dataframe['url'] = [ssrn_url[i] for i in ssrn_dataframe.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_name</th>\n",
       "      <th>ctime</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>ssrn_date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSRN-id2610429.pdf</th>\n",
       "      <td>Barth (2015).pdf</td>\n",
       "      <td>Mon May 09 16:19:21 2016</td>\n",
       "      <td>Financial Accounting Research, Practice, and F...</td>\n",
       "      <td>[Barth, Mary E.]</td>\n",
       "      <td>2015/05/26</td>\n",
       "      <td>http://papers.ssrn.com/sol3/papers.cfm?abstrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSRN-id1786360.pdf</th>\n",
       "      <td>Zeisberger, Langer, Weber (2011).pdf</td>\n",
       "      <td>Mon May 09 16:17:53 2016</td>\n",
       "      <td>Do Changes in Reporting Frequency Really Influ...</td>\n",
       "      <td>[Zeisberger, Stefan , Langer, Thomas , Weber, ...</td>\n",
       "      <td>2011/03/20</td>\n",
       "      <td>http://papers.ssrn.com/sol3/papers.cfm?abstrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSRN-id2596182.pdf</th>\n",
       "      <td>Ewert, Wagenhofer (2015).pdf</td>\n",
       "      <td>Mon May 09 16:12:42 2016</td>\n",
       "      <td>Why More Forward-Looking Accounting Standards ...</td>\n",
       "      <td>[Ewert, Ralf , Wagenhofer, Alfred ]</td>\n",
       "      <td>2015/04/20</td>\n",
       "      <td>http://papers.ssrn.com/sol3/papers.cfm?abstrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSRN-id2373877.pdf</th>\n",
       "      <td>Bonetti, Cho, Michelon (2014).pdf</td>\n",
       "      <td>Mon May 09 16:12:42 2016</td>\n",
       "      <td>Environmental Disclosure and the Cost of Capit...</td>\n",
       "      <td>[Bonetti, Pietro , Cho, Charles H., Michelon, ...</td>\n",
       "      <td>2014/01/02</td>\n",
       "      <td>http://papers.ssrn.com/sol3/papers.cfm?abstrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSRN-id2678836.pdf</th>\n",
       "      <td>Chyz, Gaertner (2015).pdf</td>\n",
       "      <td>Mon May 09 16:12:43 2016</td>\n",
       "      <td>Can Paying 'Too Much' Tax Contribute to Forced...</td>\n",
       "      <td>[Chyz, James , Gaertner, Fabio B.]</td>\n",
       "      <td>2015/10/23</td>\n",
       "      <td>http://papers.ssrn.com/sol3/papers.cfm?abstrac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                new_name  \\\n",
       "SSRN-id2610429.pdf                      Barth (2015).pdf   \n",
       "SSRN-id1786360.pdf  Zeisberger, Langer, Weber (2011).pdf   \n",
       "SSRN-id2596182.pdf          Ewert, Wagenhofer (2015).pdf   \n",
       "SSRN-id2373877.pdf     Bonetti, Cho, Michelon (2014).pdf   \n",
       "SSRN-id2678836.pdf             Chyz, Gaertner (2015).pdf   \n",
       "\n",
       "                                       ctime  \\\n",
       "SSRN-id2610429.pdf  Mon May 09 16:19:21 2016   \n",
       "SSRN-id1786360.pdf  Mon May 09 16:17:53 2016   \n",
       "SSRN-id2596182.pdf  Mon May 09 16:12:42 2016   \n",
       "SSRN-id2373877.pdf  Mon May 09 16:12:42 2016   \n",
       "SSRN-id2678836.pdf  Mon May 09 16:12:43 2016   \n",
       "\n",
       "                                                                title  \\\n",
       "SSRN-id2610429.pdf  Financial Accounting Research, Practice, and F...   \n",
       "SSRN-id1786360.pdf  Do Changes in Reporting Frequency Really Influ...   \n",
       "SSRN-id2596182.pdf  Why More Forward-Looking Accounting Standards ...   \n",
       "SSRN-id2373877.pdf  Environmental Disclosure and the Cost of Capit...   \n",
       "SSRN-id2678836.pdf  Can Paying 'Too Much' Tax Contribute to Forced...   \n",
       "\n",
       "                                                              authors  \\\n",
       "SSRN-id2610429.pdf                                   [Barth, Mary E.]   \n",
       "SSRN-id1786360.pdf  [Zeisberger, Stefan , Langer, Thomas , Weber, ...   \n",
       "SSRN-id2596182.pdf                [Ewert, Ralf , Wagenhofer, Alfred ]   \n",
       "SSRN-id2373877.pdf  [Bonetti, Pietro , Cho, Charles H., Michelon, ...   \n",
       "SSRN-id2678836.pdf                 [Chyz, James , Gaertner, Fabio B.]   \n",
       "\n",
       "                     ssrn_date  \\\n",
       "SSRN-id2610429.pdf  2015/05/26   \n",
       "SSRN-id1786360.pdf  2011/03/20   \n",
       "SSRN-id2596182.pdf  2015/04/20   \n",
       "SSRN-id2373877.pdf  2014/01/02   \n",
       "SSRN-id2678836.pdf  2015/10/23   \n",
       "\n",
       "                                                                  url  \n",
       "SSRN-id2610429.pdf  http://papers.ssrn.com/sol3/papers.cfm?abstrac...  \n",
       "SSRN-id1786360.pdf  http://papers.ssrn.com/sol3/papers.cfm?abstrac...  \n",
       "SSRN-id2596182.pdf  http://papers.ssrn.com/sol3/papers.cfm?abstrac...  \n",
       "SSRN-id2373877.pdf  http://papers.ssrn.com/sol3/papers.cfm?abstrac...  \n",
       "SSRN-id2678836.pdf  http://papers.ssrn.com/sol3/papers.cfm?abstrac...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily save the dataframe to Excel using `.to_csv()`  \n",
    "**Note:** One of the major improvements of Python 3 is improved support for unicode.  \n",
    "Python 2.7 often gives errors that relate to encoding, these can be very annoying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssrn_dataframe.to_csv('ssrn_index.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
